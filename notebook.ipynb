{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’­ğŸ•°ï¸ğŸ”ì¸ì…‰ì…˜ -> ğŸ’­ğŸ•°ï¸ğŸ”\n",
      "ğŸŒ¿ğŸŒŠğŸŒŒì•„ë°”íƒ€ -> ğŸŒ¿ğŸŒŠğŸŒŒ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì¸ì…‰ì…˜', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ğŸ’­ğŸ•°ï¸ğŸ”', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì•„ë°”íƒ€', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ğŸŒ¿ğŸŒŠğŸŒŒ', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import  ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from operator import itemgetter\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# ì˜ˆì‹œ ë°ì´í„° ì •ì˜\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"íƒ€ì´íƒ€ë‹‰\",\n",
    "        \"output\": \"ğŸš¢ğŸ’‘â„ï¸\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ë§¤íŠ¸ë¦­ìŠ¤\",\n",
    "        \"output\": \"ğŸ•¶ï¸ğŸ’ŠğŸ¤–\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì¥¬ë¼ê¸° ê³µì›\",\n",
    "        \"output\": \"ğŸ¦–ğŸƒğŸŒ´\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"í•´ë¦¬ í¬í„°\",\n",
    "        \"output\": \"âš¡ğŸ§™â€â™‚ï¸ğŸª„\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\")\n",
    "    ]),\n",
    ")\n",
    "\n",
    "# ë©”ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì˜í™” ì œëª©ì„ ë°›ì•„ì„œ ê·¸ ì˜í™”ë¥¼ ê°€ì¥ ì˜ í‘œí˜„í•˜ëŠ” 3ê°œì˜ ì´ëª¨ì§€ë¡œ ì‘ë‹µí•˜ëŠ” assistantì…ë‹ˆë‹¤. ë°˜ë“œì‹œ 3ê°œì˜ ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\"\n",
    ")\n",
    "\n",
    "# LLM ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(chat_history=memory.load_memory_variables) \n",
    "    | {\"input\": lambda x: x[\"input\"], \"chat_history\": lambda x: x[\"chat_history\"]}\n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_chain(user_input):\n",
    "    result = chain.invoke({\"input\": user_input})\n",
    "    memory.save_context({\"input\": user_input}, {\"output\": result})\n",
    "    return result\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì˜í™” í…ŒìŠ¤íŠ¸\n",
    "run_chain(\"ì¸ì…‰ì…˜\")\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì˜í™” í…ŒìŠ¤íŠ¸\n",
    "run_chain(\"ì•„ë°”íƒ€\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ í™•ì¸\n",
    "memory.load_memory_variables({})[\"chat_history\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
